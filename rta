#!/usr/bin/env python3
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import os
import time
from scipy.signal import resample
import argparse
from AudioSource import  RealTimeAudioSource, FileAudioSource
from AppMode import RTAMode, SPLMode, AutocorrelationFeedbackMode

# Parameters
SCREEN_WIDTH = 1920
SCREEN_HEIGHT = 480
def get_plotsize():
    fig = plt.figure()
    dpi = fig.get_dpi()
    return (SCREEN_WIDTH/dpi, SCREEN_HEIGHT/dpi)
plotsize = get_plotsize()

# Update the dimensions of the fft_data and vol_data arrays
SPL_TIME_BINS = SCREEN_WIDTH
SPL_VOL_BINS = SCREEN_HEIGHT
vol_data = np.zeros(SPL_TIME_BINS)

FFT_TIME_BINS = SCREEN_HEIGHT
FFT_FREQ_BINS = SCREEN_WIDTH // 2 + 1
fft_data = np.zeros((FFT_FREQ_BINS, FFT_TIME_BINS))

ACF_TIME_BINS = SCREEN_HEIGHT
ACF_FREQ_BINS = SCREEN_WIDTH // 2 + 1
acf_data = np.zeros((ACF_FREQ_BINS, ACF_TIME_BINS))

def compute_volume(signal):
    global vol_data
    # Compute RMS (root mean square) volume of the signal
    rms = np.sqrt(np.mean(signal ** 2))
    spl = round(20 * np.log10(np.where(rms < 1e-6, 1e-6, rms)),1)  # Convert to dB
    return spl

def compute_smoothed_fft(signal, samplerate, previous_fft=None, alpha=0.2):
    pass

class AudioVisualizer:
    def __init__(self):
        self.spl_mode = SPLMode(vol_data, plotsize = plotsize)
        self.rta_mode = None
        self.acf_mode = None
        self.current_mode = self.spl_mode # initial mode

    def switch_mode(self, mode_name):
        if mode_name == 'RTA':
            pass #self.current_mode = self.rta_mode
        elif mode_name == 'SPL':
            self.current_mode = self.spl_mode
            self.current_mode.setup_plot(vol_data, plotsize)
        elif mode_name == 'Autocorr':
            pass# self.current_mode = self.acf_mode
        else:
            raise ValueError(f"Invalid mode: {mode_name}")
        self.redraw()

    def redraw(self):
        global SCREEN_HEIGHT, SCREEN_WIDTH
        plt.close(self.current_mode.fig)
        self.current_mode.setup_plot(plotsize)

    def process_audio_chunk(self, audio_chunk, samplerate):
        compute_volume(audio_chunk)    
        compute_smoothed_fft(audio_chunk, samplerate)
        if self.current_mode == self.spl_mode:
            self.current_mode.update_plot(vol_data[-1])

def scan_buttons():
    # Simulate scanning for button presses
    return None

if __name__ == '__main__':
    argparse = argparse.ArgumentParser(description='Audio Visualizer')
    argparse.add_argument('--mode', choices=['SPL', 'RTA','Autocorr'], default="SPL", help='Mode to run the visualizer in')
    # change to default once we have hardware
    argparse.add_argument('--source', type=str, default='testdata', help='Use test data instead of real-time audio')
    argparse.add_argument('--windowsize', type=int, default=16384, help='Window size for FFT')
    args = argparse.parse_args()

    windowsize = int(args.windowsize)
    if args.source == 'testdata':
        audio_source = FileAudioSource('testdata', chunksize=windowsize)
        samplerate = 48000
    else:
        samplerate = 44100 # for now - need to get this from the audio source
        audio_source = RealTimeAudioSource(chunksize=windowsize)

    visualizer = AudioVisualizer()
    try:
        while True:
            button_press = scan_buttons()
            if button_press:
                pass
                #visualizer.switch_mode(button_press)                
            chunk = next(audio_source)
            visualizer.process_audio_chunk(chunk, samplerate)

    except KeyboardInterrupt:
        print('Goodbye')
