#!/usr/bin/env python3
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import os
from scipy.signal import resample

def enforce_sample_rate(audio_data, current_rate, target_rate):
    if current_rate != target_rate:
        num_samples = int(len(audio_data) * target_rate / current_rate)
        audio_data = resample(audio_data, num_samples)
    return audio_data

def compute_smoothed_fft(signal, sample_rate, previous_fft=None, alpha=0.2):
    windowed_signal = signal * np.hanning(len(signal))
    freqs = np.fft.rfftfreq(len(signal), 1.0 / sample_rate)
    fft_result = np.abs(np.fft.rfft(windowed_signal))

    # Smoothing with exponential moving average (EMA)
    if previous_fft is not None:
        smoothed_fft = alpha * fft_result + (1 - alpha) * previous_fft
    else:
        smoothed_fft = fft_result

    # Avoid log10 of zero or negative values by adding a small constant
    smoothed_fft = np.clip(smoothed_fft, a_min=1e-10, a_max=None)
    return freqs, 20 * np.log10(smoothed_fft)  # Return magnitude in dB

# Periodic update function for waterfall plot
def update_waterfall_plot(fft_data, img, new_fft_data):
    # Shift existing data upwards and append new FFT data at the bottom
    fft_data = np.roll(fft_data, -1, axis=0)
    fft_data[-1, :] = new_fft_data

    # Update the image data
    img.set_data(fft_data)
    img.autoscale()

    # Refresh the plot with updated data
    plt.draw()
    plt.pause(0.001)  # Small pause to allow plot to refresh smoothly

if __name__ == '__main__':
    # Parameters
    WINDOW_SIZE_MS = 100  # Window size in milliseconds
    HOP_SIZE_MS = 25      # Hop size for 75% overlap
    UPDATE_RATE_HZ = 4    # Screen update rate (4 Hz)
    SMOOTHING_ALPHA = 0.2 # Smoothing factor for FFT
    TARGET_SAMPLE_RATE = 48000  # Desired sample rate for the application

    # Set up the plot
    plt.figure(figsize=(19.2, 10.8))  # 1920x1080 display size in inches
    plt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.1)  # Adjust margins

    n_time_bins = 100  # Number of time steps to display
    window_size = int(TARGET_SAMPLE_RATE * WINDOW_SIZE_MS / 1000)
    n_freq_bins = window_size // 2 + 1

    fft_data = np.zeros((n_time_bins, n_freq_bins))
    # Set up the plot with updated extent
    img = plt.imshow(fft_data, aspect='auto', origin='lower', cmap='inferno', extent=[40, 20000, 0, n_time_bins])

    plt.xlabel('Hz')
    plt.xscale('log', base=2)

    def label_ticks(hz):
        if hz < 1000:
            return f'{hz:d}'
        k,c = divmod(hz, 1000)
        c = c // 100
        if c == 0:
            return f'{k:d}k'
        return f'{k:d}k{c:d}'

    ticks = [round(40 * 2 ** (i/3)) for i in range(27)] + [20000]
    plt.xticks(ticks, [label_ticks(tick) for tick in ticks])
    plt.show(block=False)

    # Adjust figure size to match your display resolution and remove padding
    plt.figure(figsize=(19.2, 10.8))  # Size in inches for a 1920x1080 display
    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Full window, no padding

    try:
        while True:
            for f in os.listdir('testdata'):
                if not f.endswith('.wav'):
                    continue

                audio_data, sample_rate = sf.read(os.path.join('testdata', f))

                # Enforce fixed sample rate
                audio_data = enforce_sample_rate(audio_data, sample_rate, TARGET_SAMPLE_RATE)
                sample_rate = TARGET_SAMPLE_RATE

                if len(audio_data.shape) == 2:  # Check if stereo
                    audio_data = audio_data.mean(axis=1)  # Convert to mono
                audio_data = audio_data.astype(np.float32)  # Convert to float
                audio_data /= np.max(np.abs(audio_data))  # Normalize to range [-1, 1]

                # Convert hop size to samples
                hop_size = int(sample_rate * HOP_SIZE_MS / 1000)

                # Update the dimensions of the fft_data array
                fft_data = np.zeros((n_time_bins, n_freq_bins))
                img.set_data(fft_data)  # Update the image data dimensions

                # Process the audio in a streaming fashion
                previous_fft = None
                for i in range(0, len(audio_data) - window_size, hop_size):
                    audio_segment = audio_data[i:i + window_size]
                    freqs, smoothed_fft = compute_smoothed_fft(audio_segment, sample_rate, previous_fft, SMOOTHING_ALPHA)

                    # Update the waterfall display
                    update_waterfall_plot(fft_data, img, smoothed_fft)
                    previous_fft = smoothed_fft  # Store for smoothing

    except KeyboardInterrupt:
        print('Goodbye')
